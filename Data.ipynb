{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, folderpath):\n",
    "        self.path = folderpath\n",
    "\n",
    "    dataset = None\n",
    "\n",
    "    def merge_x_and_y(self,x_file,y_file):\n",
    "        merged_y = pd.read_csv(y_file)\n",
    "        merged_x = pd.read_csv(x_file)\n",
    "        merged_y = merged_y.iloc[:, 1:]\n",
    "        dataset = pd.merge(merged_x,merged_y, on=['Year','Tiker'])\n",
    "\n",
    "    def exportDataset(self):\n",
    "        self.dataset.to_csv('dataset.csv')\n",
    "\n",
    "class X_data(Dataset):\n",
    "    \n",
    "    def __init__(self, folderpath):\n",
    "        super().__init__(folderpath)\n",
    "    \n",
    "    files = []\n",
    "    \n",
    "    def renameFiles(self):\n",
    "        folderPath = self.path\n",
    "        for file in os.listdir(folderPath):\n",
    "            if not file.endswith(\".xls\"):\n",
    "                continue\n",
    "            excel_data = pd.read_excel(file, sheet_name=None, header=None)\n",
    "            for sheet_name, sheet_data in excel_data.items():\n",
    "                a1_value = sheet_data.iloc[0, 0]  # Accessing the A1 cell\n",
    "            new_file_name = str(a1_value+\".xlsx\")\n",
    "            with pd.ExcelWriter(new_file_name, engine='xlsxwriter') as writer:\n",
    "                sheet_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            os.remove(file)\n",
    "        return self\n",
    "        \n",
    "    file_list = [file for file in os.listdir(self.path) if file.endswith(\"xlsx\")]\n",
    "\n",
    "    df_list = []\n",
    "    \n",
    "    def getFiles(self):\n",
    "        for i in range(0, len(self.file_list), 3):\n",
    "            chunk = self.file_list[i:i+3]\n",
    "            self.files.append(chunk)\n",
    "        return self\n",
    "    \n",
    "    def removeJunk(self, df_list):\n",
    "        for df in df_list:\n",
    "            if 'TTM' in df.columns:\n",
    "                df.drop('TTM',axis = 1,inplace = True)\n",
    "        return\n",
    "    \n",
    "    def extractCommonColumns(self,df_list):\n",
    "        balance_sheet_df, cash_flow_df, income_statement_df = df_list\n",
    "    \n",
    "        common_columns = set(balance_sheet_df.columns[1:]) & set(cash_flow_df.columns[1:]) & set(income_statement_df.columns[1:])\n",
    "        common_columns = list(common_columns)\n",
    "        \n",
    "        columns_to_drop = []\n",
    "        for df in df_list:\n",
    "            columns_to_drop.extend(col for col in df.columns if col not in common_columns and col != df.columns[0])\n",
    "        \n",
    "        # Drop the columns that are not common to every dataframe (except the first columns)\n",
    "        for df in df_list:\n",
    "            df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "            df.fillna(0, inplace=True)\n",
    "        \n",
    "        return balance_sheet_df, cash_flow_df, income_statement_df\n",
    "    \n",
    "    def curate_x_data(self):\n",
    "        for file in self.files:\n",
    "            balance_sheet = pd.read_excel(file[0], sheet_name=None, header=1)\n",
    "            for sheet_name, sheet_data in balance_sheet.items():\n",
    "                balance_sheet_df = sheet_data\n",
    "            cash_flow = pd.read_excel(file[1], sheet_name=None, header=1)\n",
    "            for sheet_name, sheet_data in cash_flow.items():\n",
    "                cash_flow_df = sheet_data\n",
    "            imcome_statement = pd.read_excel(file[2], sheet_name=None, header=1)\n",
    "            for sheet_name, sheet_data in imcome_statement.items():\n",
    "                income_statement_df = sheet_data\n",
    "            self.remove_junk([balance_sheet_df,cash_flow_df,income_statement_df])\n",
    "            balance_sheet_df, cash_flow_df, income_statement_df = self.extractCommonColumns([balance_sheet_df,cash_flow_df,income_statement_df])\n",
    "            \n",
    "            balance_sheet_df.to_csv(str(file[0].rstrip(\".xlsx\")+\".csv\"), index=False, header=1)\n",
    "            cash_flow_df.to_csv(str(file[1].rstrip(\".xlsx\")+\".csv\"), index=False, header=1)\n",
    "            income_statement_df.to_csv(str(file[2].rstrip(\".xlsx\")+\".csv\"), index=False, header=1)\n",
    "        return self\n",
    "    \n",
    "    def transpose_x_data(self):\n",
    "        for file in os.listdir(self.path):\n",
    "            if file.endswith(\".csv\"):\n",
    "                df = pd.read_csv(file)\n",
    "                df = df.iloc[:-1]\n",
    "                df.to_csv(file,index=False,header=1)\n",
    "                df = df = pd.read_csv(file)\n",
    "                transposed_df = df.T\n",
    "                # get 1st row as column names\n",
    "                transposed_df.columns = transposed_df.iloc[0]\n",
    "                # drop 1st row (column names)\n",
    "                transposed_df = transposed_df[1:]\n",
    "                transposed_df.to_csv(file)\n",
    "        return self\n",
    "\n",
    "    merged_list = []\n",
    "    tiker_list = []\n",
    "\n",
    "    def merge_triplets(self):\n",
    "        file_list = [file for file in os.listdir(\".\") if file.endswith(\".csv\")]\n",
    "        file_list.sort()\n",
    "        df_list = [pd.read_csv(file) for file in file_list]\n",
    "        for i in range(0, len(df_list), 3):\n",
    "            group = df_list[i:i+3]\n",
    "            merged_group = pd.concat(group, axis=1)\n",
    "            merged_group.columns = merged_group.columns.str.strip()\n",
    "            merged_group = merged_group.loc[:, ~merged_group.columns.duplicated()]\n",
    "            tiker = file_list[i].split('_')[0]\n",
    "            self.tiker_list.append(tiker)\n",
    "            merged_group['Tiker'] = tiker\n",
    "            self.merged_list.append(merged_group)\n",
    "        return self\n",
    "    \n",
    "    def drop_outliers(self):\n",
    "        dump_list = []\n",
    "        counter = 0\n",
    "        for df in self.merged_list:\n",
    "            if \"Gross Profit\" not in df.columns.to_list():\n",
    "                temp = df\n",
    "                dump_list.append(counter)\n",
    "            counter += 1 \n",
    "        for i in range(len(dump_list)-1, -1, -1):\n",
    "            self.merged_list.pop(dump_list[i])\n",
    "            self.tiker_list.pop(dump_list[i])\n",
    "        return self\n",
    "    \n",
    "    final_df = None\n",
    "    \n",
    "    def concat_x_data(self):\n",
    "        self.final_df = pd.concat(self.merged_list, join='inner', ignore_index=True)\n",
    "        self.final_df = self.final_df.rename(columns={'Unnamed: 0': 'Year'})\n",
    "        self.final_df['Year'] = self.final_df['Year'].astype(int)\n",
    "        return self\n",
    "\n",
    "    def export_x_dataset(self):\n",
    "        self.final_df.to_csv(\"X_dataset.csv\") \n",
    "    \n",
    "    def cleanup(self):\n",
    "        for file in os.listdir(\".\"):\n",
    "            if file.endswith(\".xlsx\"):\n",
    "                os.remove(file)\n",
    "        return self\n",
    "\n",
    "class Y_Data(Dataset):\n",
    "\n",
    "    def __init__(self, folderpath):\n",
    "        super().__init__(folderpath)\n",
    "\n",
    "    \n",
    "    def curate_y_data(self):\n",
    "        with open('tickers.txt', 'r') as file:\n",
    "            content_list = file.readlines()\n",
    "        content_list = [line.strip() for line in content_list]\n",
    "\n",
    "        files = [file.rstrip(\".csv\") for file in os.listdir(self.path) if file.endswith(\".csv\")]\n",
    "        for file in content_list:\n",
    "            if file not in files:\n",
    "                print(file)\n",
    "\n",
    "        for file in files:\n",
    "            df = pd.read_csv(str(file+\".csv\"))\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            filtered_df = df[df['Date'] >= '2014-01-01']\n",
    "            filtered_df = filtered_df[['Open','Date']]\n",
    "            filtered_df = filtered_df.groupby(filtered_df['Date'].dt.year).first().reset_index(drop=True)\n",
    "            filtered_df['Year'] = filtered_df['Date'].dt.year\n",
    "            filtered_df['return'] = (filtered_df['Open'] - filtered_df['Open'].shift(1)) / filtered_df['Open'].shift(1)\n",
    "            filtered_df['return'] = filtered_df['return'].shift(-1)\n",
    "            filtered_df.to_csv(str(file+\".csv\"), index=False)\n",
    "        return self\n",
    "\n",
    "    merged_list = []\n",
    "    merged_df = None\n",
    "    \n",
    "    def megre_y_data(self):\n",
    "        for file in os.listdir(\".\"):\n",
    "            if file.endswith(\".csv\"):\n",
    "                df = pd.read_csv(file)\n",
    "                df['Tiker'] = file.split('.')[0]\n",
    "                self.merged_list.append(df)\n",
    "        self.merged_df = pd.concat(self.merged_list, axis=0, ignore_index=True)\n",
    "        return self\n",
    "    \n",
    "    def export_y_dataset(self):\n",
    "        self.merged_df.to_csv(\"y_merged.csv\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
